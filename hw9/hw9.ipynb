{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "import math\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn, rnn\n",
    "from mxnet.gluon import data as gdata\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>619029.000000</td>\n",
       "      <td>619032.000000</td>\n",
       "      <td>619032.000000</td>\n",
       "      <td>619040.000000</td>\n",
       "      <td>6.190400e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>83.023334</td>\n",
       "      <td>83.778311</td>\n",
       "      <td>82.256096</td>\n",
       "      <td>83.043763</td>\n",
       "      <td>4.321823e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>97.378769</td>\n",
       "      <td>98.207519</td>\n",
       "      <td>96.507421</td>\n",
       "      <td>97.389748</td>\n",
       "      <td>8.693610e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.620000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.220000</td>\n",
       "      <td>40.620000</td>\n",
       "      <td>39.830000</td>\n",
       "      <td>40.245000</td>\n",
       "      <td>1.070320e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.590000</td>\n",
       "      <td>63.150000</td>\n",
       "      <td>62.020000</td>\n",
       "      <td>62.620000</td>\n",
       "      <td>2.082094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94.370000</td>\n",
       "      <td>95.180000</td>\n",
       "      <td>93.540000</td>\n",
       "      <td>94.410000</td>\n",
       "      <td>4.284509e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2044.000000</td>\n",
       "      <td>2067.990000</td>\n",
       "      <td>2035.110000</td>\n",
       "      <td>2049.000000</td>\n",
       "      <td>6.182376e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                open           high            low          close  \\\n",
       "count  619029.000000  619032.000000  619032.000000  619040.000000   \n",
       "mean       83.023334      83.778311      82.256096      83.043763   \n",
       "std        97.378769      98.207519      96.507421      97.389748   \n",
       "min         1.620000       1.690000       1.500000       1.590000   \n",
       "25%        40.220000      40.620000      39.830000      40.245000   \n",
       "50%        62.590000      63.150000      62.020000      62.620000   \n",
       "75%        94.370000      95.180000      93.540000      94.410000   \n",
       "max      2044.000000    2067.990000    2035.110000    2049.000000   \n",
       "\n",
       "             volume  \n",
       "count  6.190400e+05  \n",
       "mean   4.321823e+06  \n",
       "std    8.693610e+06  \n",
       "min    0.000000e+00  \n",
       "25%    1.070320e+06  \n",
       "50%    2.082094e+06  \n",
       "75%    4.284509e+06  \n",
       "max    6.182376e+08  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_stocks_5yr.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.ffill().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>2.712706</td>\n",
       "      <td>17.180717</td>\n",
       "      <td>16.851275</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>15.944635</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>2.700690</td>\n",
       "      <td>17.152094</td>\n",
       "      <td>16.639512</td>\n",
       "      <td>2.671386</td>\n",
       "      <td>15.999537</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>2.670694</td>\n",
       "      <td>16.924995</td>\n",
       "      <td>16.638363</td>\n",
       "      <td>2.658159</td>\n",
       "      <td>15.910579</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>2.660260</td>\n",
       "      <td>17.256185</td>\n",
       "      <td>16.783332</td>\n",
       "      <td>2.685123</td>\n",
       "      <td>16.143715</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>2.704042</td>\n",
       "      <td>17.106322</td>\n",
       "      <td>15.824342</td>\n",
       "      <td>2.638343</td>\n",
       "      <td>17.277486</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      open       high        low     close     volume Name  year\n",
       "0 2013-02-08  2.712706  17.180717  16.851275  2.691243  15.944635  AAL  2013\n",
       "1 2013-02-11  2.700690  17.152094  16.639512  2.671386  15.999537  AAL  2013\n",
       "2 2013-02-12  2.670694  16.924995  16.638363  2.658159  15.910579  AAL  2013\n",
       "3 2013-02-13  2.660260  17.256185  16.783332  2.685123  16.143715  AAL  2013\n",
       "4 2013-02-14  2.704042  17.106322  15.824342  2.638343  17.277486  AAL  2013"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1['open'] = np.log(df1['open'])\n",
    "df1['high'] = 10* (np.log(df1['high']) - np.log(df1['open']))\n",
    "df1['low'] = 10* (np.log(df1['low']) - np.log(df1['open']))\n",
    "df1['close'] = np.log(df1['close'])\n",
    "df1['volume'] = np.log(df1['volume'])\n",
    "df1.loc[:, 'date'] = pd.to_datetime(df1.loc[:,'date'], format=\"%Y/%m/%d\")\n",
    "df1['year'] = pd.DatetimeIndex(df1['date']).year\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[df1['year'] == 2018]\n",
    "df2.to_csv (r'test.csv', index = None, header=True)\n",
    "df3 = df1[df1['year'] != 2018]\n",
    "df3.to_csv (r'train.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = list(np.unique(df3[df3['year'] == 2017].Name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test feature matrix: \n",
      " \n",
      "[[ 4.210942   4.213904   4.2419024 ...  4.260706   4.2040954  4.222298 ]\n",
      " [27.802025  28.027933  28.009087  ... 28.199827  27.955805  27.949581 ]\n",
      " [27.72068   27.752186  27.859013  ... 27.727163  27.555634  27.777302 ]\n",
      " ...\n",
      " [28.142883  28.150318  28.246767  ... 28.252508  28.229082  28.307703 ]\n",
      " [ 4.2734666  4.278054   4.2840004 ...  4.301765   4.2941513  4.302171 ]\n",
      " [14.574242  14.660737  14.745314  ... 14.901385  15.409698  15.327316 ]]\n",
      "<NDArray 2525x26 @cpu(0)>\n",
      "train feature matrix: \n",
      " \n",
      "[[ 3.8082168  3.8104331  3.8024313 ...  4.207822   4.2112384  4.2121277]\n",
      " [24.772491  24.729116  24.6991    ... 27.745897  27.740746  27.753443 ]\n",
      " [24.695015  24.566221  24.598486  ... 27.699837  27.672344  27.656794 ]\n",
      " ...\n",
      " [22.293644  22.405806  22.458382  ... 28.25052   28.238503  28.2227   ]\n",
      " [ 3.4980216  3.5043554  3.5186841 ...  4.2828965  4.2820683  4.2772217]\n",
      " [14.770726  14.211676  14.308546  ... 13.963733  13.473722  14.34856  ]]\n",
      "<NDArray 2525x1233 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "def create_feature(df3):\n",
    "    \n",
    "    grouped = df3.groupby('date')\n",
    "    i = 0\n",
    "    price = nd.zeros((2525, len(grouped)))\n",
    "    \n",
    "    for date, group in grouped:\n",
    "        rec = grouped.get_group(date).reset_index(drop = True)\n",
    "        price_date = np.zeros((505,5))\n",
    "        for a in range(len(name)):\n",
    "            if len(rec[rec['Name'] == name[a]]) > 0:\n",
    "                price_date[a] = rec[rec['Name'] == name[a]].iloc[:,1:6].values\n",
    "            '''\n",
    "            else:\n",
    "                print('here == 0: ', name[a])\n",
    "                unnamed.append(name[a])\n",
    "            '''    \n",
    "        price[:,i] = price_date.flatten()\n",
    "        i+=1\n",
    "    return price\n",
    "\n",
    "test_feature = create_feature(df2) #test\n",
    "print('test feature matrix: \\n',test_feature)\n",
    "\n",
    "train_feature = create_feature(df3) #train\n",
    "print('train feature matrix: \\n',train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature2 = train_feature\n",
    "for i in range(2525):\n",
    "    if train_feature2[i].min() == 0:\n",
    "        max_index = np.nonzero(train_feature2[i])[0].max()\n",
    "        min_index = np.nonzero(train_feature2[i])[0].min()\n",
    "        if max_index == 1232:\n",
    "            #print(train_feature2[i])\n",
    "            train_feature2[i,:min_index+1] = train_feature2[i,min_index+1]\n",
    "            #print(train_feature2[i])\n",
    "        elif min_index == 0:\n",
    "            train_feature2[i,:max_index+1:] = train_feature2[i,max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature2 = train_feature2.T\n",
    "feature = train_feature2.asnumpy()\n",
    "np.savetxt(\"feature.csv\", feature, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this when import from csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the label (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(df3):\n",
    "    \n",
    "    grouped = df3.groupby('date')\n",
    "    i = 0\n",
    "    price = nd.zeros((505, len(grouped)))\n",
    "    \n",
    "    for date, group in grouped:\n",
    "        rec = grouped.get_group(date).reset_index(drop = True)\n",
    "        price_date = nd.zeros((505,))\n",
    "        for a in range(len(name)):\n",
    "            if len(rec[rec['Name'] == name[a]]) > 0:\n",
    "                price_date[a] = rec[rec['Name'] == name[a]].iloc[:,1].values\n",
    "        price[:,i] = price_date\n",
    "        i+=1\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label matrix: \n",
      " \n",
      "[[3.8082168 3.8104331 3.8024313 ... 4.207822  4.2112384 4.2121277]\n",
      " [2.712706  2.7006898 2.6706944 ... 3.9665112 3.9598603 3.9592881]\n",
      " [4.361058  4.3650074 4.3616962 ... 4.622224  4.6037693 4.603669 ]\n",
      " ...\n",
      " [4.3177547 4.3274384 4.3261175 ... 4.787492  4.7889905 4.8019695]\n",
      " [3.179303  3.1838703 3.189653  ... 3.9275026 3.930256  3.937301 ]\n",
      " [3.4753768 3.4983242 3.508556  ... 4.284827  4.2834487 4.284276 ]]\n",
      "<NDArray 505x1233 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "train_label = create_label(df3)\n",
    "print('train label matrix: \\n',train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test label matrix: \n",
      " \n",
      "[[4.210942  4.213904  4.2419024 ... 4.260706  4.2040954 4.222298 ]\n",
      " [3.9575698 3.9676468 3.960432  ... 3.9510515 3.8983297 3.9300594]\n",
      " [4.61413   4.6673937 4.679814  ... 4.7278304 4.6847205 4.719302 ]\n",
      " ...\n",
      " [4.7957907 4.825991  4.8306313 ... 4.8266325 4.7957907 4.801148 ]\n",
      " [3.9545076 3.9257286 3.9322176 ... 3.980429  3.9201896 3.955657 ]\n",
      " [4.284138  4.2734666 4.287029  ... 4.339119  4.2868915 4.286341 ]]\n",
      "<NDArray 505x26 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "test_label = create_label(df2)\n",
    "print('test label matrix: \\n',test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label2 = train_label\n",
    "for i in range(505):\n",
    "    if train_label2[i].min() == 0:\n",
    "        max_index = np.nonzero(train_label2[i])[0].max()\n",
    "        min_index = np.nonzero(train_label2[i])[0].min()\n",
    "        if max_index == 1232:\n",
    "            #print(train_feature2[i])\n",
    "            train_label2[i,:min_index+1] = train_label2[i,min_index+1]\n",
    "            #print(train_feature2[i])\n",
    "        elif min_index == 0:\n",
    "            train_label2[i,:max_index+1:] = train_label2[i,max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.T\n",
    "\n",
    "train_label2 = train_label2.T\n",
    "label = train_label2.asnumpy()\n",
    "np.savetxt(\"label.csv\", label, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label file Read from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv(\"feature.csv\", header = None)\n",
    "featureMatrix = nd.array(feature_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\"label.csv\", header = None)\n",
    "labelMatrix = nd.array(label_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007, 2525) (1007, 505)\n"
     ]
    }
   ],
   "source": [
    "ctx = d2l.try_gpu()\n",
    "featureMatrix = featureMatrix[226:1233,:].as_in_context(ctx)\n",
    "labelMatrix = labelMatrix[226:,:].as_in_context(ctx)\n",
    "print(featureMatrix.shape, labelMatrix.shape)\n",
    "train_iter = gdata.DataLoader(gdata.ArrayDataset(featureMatrix, labelMatrix), batch_size=20, shuffle=False,last_batch = 'discard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNReg(nn.Block):\n",
    "    def __init__(self, rnn_layer, out_size=505, **kwargs):\n",
    "        super(RNNReg, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.out_size = out_size # we only predict the open price next day\n",
    "        self.dense = nn.Dense(out_size)\n",
    "\n",
    "    def forward(self, inputs, state):\n",
    "        # the shape is (batch_size, time_step_forward, sample_length)\n",
    "        X = inputs.reshape(1, inputs.shape[0], inputs.shape[1])\n",
    "        Y, state = self.rnn(X, state)\n",
    "        output = self.dense(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_gluon(inputs, step_forward, model, ctx):\n",
    "    # inputs should be of dimension (days of that year)*2525\n",
    "    state = model.begin_state(batch_size=1, ctx=ctx)\n",
    "    output = [inputs[0]]\n",
    "    for t in range(len(inputs) + step_forward - 1):\n",
    "        X = nd.array(output[-1], ctx=ctx)\n",
    "        (Y, state) = model(X, state)\n",
    "        if t < len(inputs) - 1:\n",
    "            output.append(inputs[t+1])\n",
    "        else:\n",
    "            output.append(Y.reshape((-1, Y.shape[-1])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping_gluon(model, theta, ctx):\n",
    "    params = [p.data() for p in model.collect_params().values()]\n",
    "    d2l.grad_clipping(params, theta, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is the dummy data, need to be replaced with\n",
    "# X = (batch_size, all_data_per_day), Y = (batch_size, all_open_price_next_day)\n",
    "# where X and Y are both ndarrays, so that just treat them as train_features and train_labels\n",
    "#train_features = nd.zeros((60, 2525), ctx=ctx)\n",
    "#train_labels = nd.ones((60, 505), ctx=ctx)\n",
    "\n",
    "\n",
    "def train_and_predict_rnn_gluon(model, num_hiddens, data_iter, ctx, num_epochs,\\\n",
    "                                num_steps, lr, clipping_theta, batch_size):\n",
    "    loss = gloss.L2Loss()\n",
    "    model.initialize(ctx=ctx, force_reinit=True, init=init.Normal(0.01))\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
    "                            {'learning_rate': lr, 'momentum': 0, 'wd': 0})\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        state = model.begin_state(batch_size=batch_size, ctx=ctx)\n",
    "        for X, Y in data_iter:\n",
    "            i += 1\n",
    "            for s in state:\n",
    "                s.detach()\n",
    "            with autograd.record():\n",
    "                (output, state) = model(X, state)\n",
    "                # y = Y.T.reshape((-1,))\n",
    "                l = loss(output, Y).mean()\n",
    "                print(l.asscalar())\n",
    "                if i == 26:\n",
    "                    checkX = X\n",
    "                    checkY = Y\n",
    "                    checkout = output\n",
    "            l.backward()\n",
    "            # Clip the gradient\n",
    "            grad_clipping_gluon(model, clipping_theta, ctx)\n",
    "            # Since the error has already taken the mean, the gradient does\n",
    "            # not need to be averaged\n",
    "            trainer.step(1)\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print('epoch: ', epoch+1, ', loss: ', l.asscalar())\n",
    "    #return checkX, checkY, checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(20):\n",
    "    for j in range(505):\n",
    "        count+=1\n",
    "        if count == 5051:\n",
    "            print(checkout[i,j].asscalar())\n",
    "        elif count == 5053:\n",
    "            print(checkout[i,j].asscalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.526017\n",
      "10.274599\n",
      "9.843109\n",
      "9.211667\n",
      "8.657918\n",
      "8.220795\n",
      "7.7461762\n",
      "7.198845\n",
      "6.800077\n",
      "6.244428\n",
      "5.8931036\n",
      "5.5684977\n",
      "5.1773596\n",
      "4.78346\n",
      "4.457508\n",
      "4.0979896\n",
      "3.758126\n",
      "3.4173877\n",
      "3.077883\n",
      "2.7611384\n",
      "2.428865\n",
      "2.1038404\n",
      "1.8628323\n",
      "1.6350174\n",
      "1.3907385\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1\n",
    "num_epochs, batch_size, lr, clipping_theta = 2, 20, 10, 1e-3\n",
    "\n",
    "num_hiddens = 1024\n",
    "rnn_layer = rnn.RNN(num_hiddens)\n",
    "rnn_layer.initialize(ctx=ctx)\n",
    "single_rnn_model = RNNReg(rnn_layer, 505)\n",
    "single_rnn_model.initialize(force_reinit=True, ctx = ctx)\n",
    "\n",
    "train_and_predict_rnn_gluon(single_rnn_model, num_hiddens, train_iter, ctx, num_epochs,\\\n",
    "                            num_steps, lr, clipping_theta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test_feature.T\n",
    "predict = predict_rnn_gluon(inputs, 1, single_rnn_model, ctx)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 30\n",
    "num_epochs, batch_size, lr, clipping_theta = 200, 20, .1, 1e-2\n",
    "\n",
    "gru_layer = rnn.GRU(num_hiddens)\n",
    "gru_layer.initialize(ctx=ctx)\n",
    "gru_model = RNNReg(rnn_layer, 505)\n",
    "gru_model.initialize(force_reinit=True, ctx = ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_predict_rnn_gluon(gru_model, num_hiddens, train_iter, ctx, num_epochs,\\\n",
    "                            num_steps, lr, clipping_theta, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = test_feature.T\n",
    "predict = predict_rnn_gluon(inputs, 1, single_rnn_model, ctx)\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
